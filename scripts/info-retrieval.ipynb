{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vitaf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import os\n",
    "# no lowercasing here, as we do it ourselves later.\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=False)\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading and inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../data/trec-medline.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>AB</th>\n",
       "      <th>AD</th>\n",
       "      <th>CY</th>\n",
       "      <th>DA</th>\n",
       "      <th>DCOM</th>\n",
       "      <th>DP</th>\n",
       "      <th>EDAT</th>\n",
       "      <th>ID</th>\n",
       "      <th>IP</th>\n",
       "      <th>...</th>\n",
       "      <th>CON</th>\n",
       "      <th>CIN</th>\n",
       "      <th>RPF</th>\n",
       "      <th>RPI</th>\n",
       "      <th>SPIN</th>\n",
       "      <th>RIN</th>\n",
       "      <th>ROF</th>\n",
       "      <th>ORI</th>\n",
       "      <th>UOF</th>\n",
       "      <th>UIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We present an evaluation of the accuracy and p...</td>\n",
       "      <td>Department of Molecular Biology and Skaggs Ins...</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>20011105.0</td>\n",
       "      <td>20020401.0</td>\n",
       "      <td>2001 Sep</td>\n",
       "      <td>2001/11/06 10:00</td>\n",
       "      <td>GM56879/GM/NIGMS</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>An analysis is presented of experimental versu...</td>\n",
       "      <td>Department of Medical Biosciences, Medical Bio...</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>20011105.0</td>\n",
       "      <td>20020401.0</td>\n",
       "      <td>2001 Sep</td>\n",
       "      <td>2001/11/06 10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The global fold of maltose binding protein in ...</td>\n",
       "      <td>Protein Engineering Network Center of Excellen...</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>20011105.0</td>\n",
       "      <td>20020401.0</td>\n",
       "      <td>2001 Sep</td>\n",
       "      <td>2001/11/06 10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A general method is presented for magnetic fie...</td>\n",
       "      <td>Molecular Structure Division, National Institu...</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>20011105.0</td>\n",
       "      <td>20020401.0</td>\n",
       "      <td>2001 Sep</td>\n",
       "      <td>2001/11/06 10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The dependence between the anomeric carbon che...</td>\n",
       "      <td>Department of Chemistry &amp; Biochemistry, Univer...</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>20011105.0</td>\n",
       "      <td>20020401.0</td>\n",
       "      <td>2001 Sep</td>\n",
       "      <td>2001/11/06 10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                                 AB  \\\n",
       "0      1  We present an evaluation of the accuracy and p...   \n",
       "1      2  An analysis is presented of experimental versu...   \n",
       "2      3  The global fold of maltose binding protein in ...   \n",
       "3      4  A general method is presented for magnetic fie...   \n",
       "4      5  The dependence between the anomeric carbon che...   \n",
       "\n",
       "                                                  AD           CY          DA  \\\n",
       "0  Department of Molecular Biology and Skaggs Ins...  Netherlands  20011105.0   \n",
       "1  Department of Medical Biosciences, Medical Bio...  Netherlands  20011105.0   \n",
       "2  Protein Engineering Network Center of Excellen...  Netherlands  20011105.0   \n",
       "3  Molecular Structure Division, National Institu...  Netherlands  20011105.0   \n",
       "4  Department of Chemistry & Biochemistry, Univer...  Netherlands  20011105.0   \n",
       "\n",
       "         DCOM        DP              EDAT                ID IP  ...  CON  CIN  \\\n",
       "0  20020401.0  2001 Sep  2001/11/06 10:00  GM56879/GM/NIGMS  1  ...  NaN  NaN   \n",
       "1  20020401.0  2001 Sep  2001/11/06 10:00               NaN  1  ...  NaN  NaN   \n",
       "2  20020401.0  2001 Sep  2001/11/06 10:00               NaN  1  ...  NaN  NaN   \n",
       "3  20020401.0  2001 Sep  2001/11/06 10:00               NaN  1  ...  NaN  NaN   \n",
       "4  20020401.0  2001 Sep  2001/11/06 10:00               NaN  1  ...  NaN  NaN   \n",
       "\n",
       "   RPF  RPI SPIN  RIN  ROF  ORI  UOF  UIN  \n",
       "0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_rows = df.iloc[::2].reset_index(drop=True)[[\"index\"]]\n",
    "id_rows[\"index\"] = id_rows[\"index\"].apply(lambda x: int(x[\"_id\"]))\n",
    "content_rows = df.iloc[1::2].reset_index(drop=True).drop(labels=[\"index\"], axis=1)\n",
    "combined_df = pd.concat([id_rows, content_rows], axis=1)\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>AB</th>\n",
       "      <th>PMID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We present an evaluation of the accuracy and p...</td>\n",
       "      <td>11693564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>An analysis is presented of experimental versu...</td>\n",
       "      <td>11693565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The global fold of maltose binding protein in ...</td>\n",
       "      <td>11693566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A general method is presented for magnetic fie...</td>\n",
       "      <td>11693567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The dependence between the anomeric carbon che...</td>\n",
       "      <td>11693568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                                 AB      PMID\n",
       "0      1  We present an evaluation of the accuracy and p...  11693564\n",
       "1      2  An analysis is presented of experimental versu...  11693565\n",
       "2      3  The global fold of maltose binding protein in ...  11693566\n",
       "3      4  A general method is presented for magnetic fie...  11693567\n",
       "4      5  The dependence between the anomeric carbon che...  11693568"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = combined_df[[\"index\", \"AB\", \"PMID\"]]\n",
    "docs = docs.astype({\"index\": int, \"PMID\": int})\n",
    "docs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index    0\n",
      "query    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# load queries\n",
    "queries = pd.DataFrame(columns=[\"index\", \"query\"])\n",
    "\n",
    "with open(\"../data/training-queries-simple.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "data = []\n",
    "for line in lines:\n",
    "    x = line.strip().split(\"\\t\")\n",
    "    if len(x) >= 2:  \n",
    "        data.append({\"index\": int(x[0]), \"query\": x[1]})\n",
    "    else:\n",
    "        raise ValueError(\"wtf\")\n",
    "queries = pd.concat([queries, pd.DataFrame(data)], ignore_index=True)\n",
    "queries.head(5)\n",
    "print(queries.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index         0\n",
      "AB       123568\n",
      "PMID          0\n",
      "dtype: int64\n",
      "402369\n",
      "401929\n"
     ]
    }
   ],
   "source": [
    "# drop missings\n",
    "print(docs.isna().sum())\n",
    "docs = docs.dropna()\n",
    "def remove_short_strings(df, column_name):\n",
    "    pattern = re.compile(r'\\W+')\n",
    "    filtered_df = df[df[column_name].apply(\n",
    "        lambda x: isinstance(x, str) and len(pattern.sub('', x)) >= 20\n",
    "    )].copy()\n",
    "    filtered_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return filtered_df\n",
    "print(docs.shape[0])\n",
    "docs = remove_short_strings(docs, \"AB\")\n",
    "print(docs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1529\n"
     ]
    }
   ],
   "source": [
    "# find max words\n",
    "max_words = docs['AB'].apply(lambda x: len(x.split())).max()\n",
    "print(max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  query_index doc_index relevant\n",
      "0           1  11642719        1\n",
      "1           1  11695244        1\n",
      "2           1  11700040        1\n",
      "3           1  11733969        1\n",
      "4           1  11741909        1\n",
      "query_index    0\n",
      "doc_index      0\n",
      "relevant       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# load query results\n",
    "query_res = pd.DataFrame(columns=[\"query_index\", \"doc_index\", \"relevant\"])\n",
    "\n",
    "with open(\"../data/training-qrels.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "data = []\n",
    "for line in lines:\n",
    "    x = line.strip().split(\"\\t\")\n",
    "    if len(x) >= 4:  \n",
    "        data.append({\"query_index\": int(x[0]), \"doc_index\": int(x[2]), \"relevant\": int(x[3])})\n",
    "    else:\n",
    "        raise ValueError(\"wtf\")\n",
    "query_res = pd.concat([query_res, pd.DataFrame(data)], ignore_index=True)\n",
    "print(query_res.head(5))\n",
    "print(query_res.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>query</th>\n",
       "      <th>relevant_docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"cyclin-dependent kinase inhibitor 1A (p21, Ci...</td>\n",
       "      <td>[11642719, 11695244, 11700040, 11733969, 11741...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"DEAD/H (Asp-Glu-Ala-Asp/His) box polypeptide ...</td>\n",
       "      <td>[12101238, 12527917]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ets variant gene 6 (TEL oncogene) in Homo sapiens</td>\n",
       "      <td>[11731410, 11861293, 11861295, 12080468, 12091...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>fibroblast growth factor 7 (keratinocyte growt...</td>\n",
       "      <td>[11937263, 11943656, 11973338, 12008951, 12016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"glycine receptor, alpha 1 (startle disease/hy...</td>\n",
       "      <td>[11580237, 11781706, 11973623, 11981020, 11981...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index                                              query  \\\n",
       "0     1  \"cyclin-dependent kinase inhibitor 1A (p21, Ci...   \n",
       "1     2  \"DEAD/H (Asp-Glu-Ala-Asp/His) box polypeptide ...   \n",
       "2     3  ets variant gene 6 (TEL oncogene) in Homo sapiens   \n",
       "3     4  fibroblast growth factor 7 (keratinocyte growt...   \n",
       "4     5  \"glycine receptor, alpha 1 (startle disease/hy...   \n",
       "\n",
       "                                       relevant_docs  \n",
       "0  [11642719, 11695244, 11700040, 11733969, 11741...  \n",
       "1                               [12101238, 12527917]  \n",
       "2  [11731410, 11861293, 11861295, 12080468, 12091...  \n",
       "3  [11937263, 11943656, 11973338, 12008951, 12016...  \n",
       "4  [11580237, 11781706, 11973623, 11981020, 11981...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine queries and results\n",
    "\n",
    "filtered_df = query_res[query_res[\"relevant\"] == 1]\n",
    "grouped_df = filtered_df.groupby('query_index')['doc_index'].apply(list).reset_index()\n",
    "grouped_df = grouped_df.rename(columns={'doc_index': 'relevant_docs'})\n",
    "queries_training = pd.concat([queries, grouped_df], axis=1)\n",
    "queries_training = queries_training.drop(columns=[\"query_index\"])\n",
    "queries_training.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>query</th>\n",
       "      <th>relevant_docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"cyclin-dependent kinase inhibitor 1A (p21, Ci...</td>\n",
       "      <td>[11642719, 11695244, 11700040, 11733969, 11741...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"DEAD/H (Asp-Glu-Ala-Asp/His) box polypeptide ...</td>\n",
       "      <td>[12101238, 12527917]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ets variant gene 6 (TEL oncogene) in Homo sapiens</td>\n",
       "      <td>[11731410, 11861293, 11861295, 12080468, 12091...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>fibroblast growth factor 7 (keratinocyte growt...</td>\n",
       "      <td>[11937263, 11943656, 11973338, 12008951, 12016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"glycine receptor, alpha 1 (startle disease/hy...</td>\n",
       "      <td>[11580237, 11781706, 11973623, 11981020, 11981...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index                                              query  \\\n",
       "0     1  \"cyclin-dependent kinase inhibitor 1A (p21, Ci...   \n",
       "1     2  \"DEAD/H (Asp-Glu-Ala-Asp/His) box polypeptide ...   \n",
       "2     3  ets variant gene 6 (TEL oncogene) in Homo sapiens   \n",
       "3     4  fibroblast growth factor 7 (keratinocyte growt...   \n",
       "4     5  \"glycine receptor, alpha 1 (startle disease/hy...   \n",
       "\n",
       "                                       relevant_docs  \n",
       "0  [11642719, 11695244, 11700040, 11733969, 11741...  \n",
       "1                               [12101238, 12527917]  \n",
       "2  [11731410, 11861293, 11861295, 12080468, 12091...  \n",
       "3  [11937263, 11943656, 11973338, 12008951, 12016...  \n",
       "4  [11580237, 11781706, 11973623, 11981020, 11981...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect final datasetsts\n",
    "queries_training.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>AB</th>\n",
       "      <th>PMID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We present an evaluation of the accuracy and p...</td>\n",
       "      <td>11693564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>An analysis is presented of experimental versu...</td>\n",
       "      <td>11693565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The global fold of maltose binding protein in ...</td>\n",
       "      <td>11693566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A general method is presented for magnetic fie...</td>\n",
       "      <td>11693567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The dependence between the anomeric carbon che...</td>\n",
       "      <td>11693568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                                 AB      PMID\n",
       "0      1  We present an evaluation of the accuracy and p...  11693564\n",
       "1      2  An analysis is presented of experimental versu...  11693565\n",
       "2      3  The global fold of maltose binding protein in ...  11693566\n",
       "3      4  A general method is presented for magnetic fie...  11693567\n",
       "4      5  The dependence between the anomeric carbon che...  11693568"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{12147208, 12147209, 11861518, 11688978, 11822867, 11714840, 12027934, 11374883, 11406125, 11042116, 11717190, 11700040, 11781193, 11781706, 11564874, 11580237, 11882578, 11846485, 11642719, 11685227, 11466351, 11841916, 11752574, 11752575, 11779460, 11740559, 11727760, 12412576, 11686318, 11441070, 11809712, 11743158, 11701948, 11749055, 11842244, 11748297, 11733969, 11731410, 11741909, 11752172, 11751405, 12161015}\n",
      "Number of relevant docs: 327\n",
      "Number of existing docs in 'docs' DataFrame: 285\n",
      "Number of missing docs: 42\n"
     ]
    }
   ],
   "source": [
    "# check if all doc ids from queries are in the dataset (after removing missings)\n",
    "unique_relevant_docs = set(queries_training['relevant_docs'].explode())\n",
    "existing_docs = unique_relevant_docs.intersection(docs.PMID)\n",
    "missing_docs = unique_relevant_docs.difference(docs.PMID)\n",
    "\n",
    "print(missing_docs)\n",
    "print(f\"Number of relevant docs: {len(unique_relevant_docs)}\")\n",
    "print(f\"Number of existing docs in 'docs' DataFrame: {len(existing_docs)}\")\n",
    "print(f\"Number of missing docs: {len(missing_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a smaller dataset\n",
    "existing_docs = set(unique_relevant_docs).intersection(set(docs['PMID']))\n",
    "\n",
    "# Select the rows from 'docs' where 'PMID' is in 'existing_docs'\n",
    "selected_docs = docs[docs['PMID'].isin(existing_docs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ofc there are missings relevant texts with no abstract. nice dataset:)\n",
    "def filter_missing_docs(doc_list):\n",
    "    return [doc for doc in doc_list if doc in existing_docs]\n",
    "    \n",
    "queries_training['relevant_docs'] = queries_training['relevant_docs'].apply(filter_missing_docs)\n",
    "# remove quries with no docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_training = queries_training[queries_training['relevant_docs'].apply(lambda x: len(x) > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final results\n",
    "queries_training = queries_training.drop(columns=[\"index\"])\n",
    "docs = docs.drop(columns=[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 401929/401929 [00:25<00:00, 15784.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 401929/401929 [09:54<00:00, 675.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing queries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 46913.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing queriess\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 9401.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB</th>\n",
       "      <th>PMID</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We present an evaluation of the accuracy and p...</td>\n",
       "      <td>11693564</td>\n",
       "      <td>[present, evaluation, accuracy, precision, rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An analysis is presented of experimental versu...</td>\n",
       "      <td>11693565</td>\n",
       "      <td>[analysis, presented, experimental, versus, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The global fold of maltose binding protein in ...</td>\n",
       "      <td>11693566</td>\n",
       "      <td>[global, fold, mal, ##tose, binding, protein, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  AB      PMID  \\\n",
       "0  We present an evaluation of the accuracy and p...  11693564   \n",
       "1  An analysis is presented of experimental versu...  11693565   \n",
       "2  The global fold of maltose binding protein in ...  11693566   \n",
       "\n",
       "                                              tokens  \n",
       "0  [present, evaluation, accuracy, precision, rel...  \n",
       "1  [analysis, presented, experimental, versus, ca...  \n",
       "2  [global, fold, mal, ##tose, binding, protein, ...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text, remove_stopwords=True):\n",
    "    copy = text\n",
    "    copy = copy.lower()\n",
    "    # remove punctuation\n",
    "    copy = re.sub(r\"[^\\w\\s]\", '', copy)\n",
    "    # remove double whitespaces.\n",
    "    copy = re.sub(r'\\s+', ' ', copy).strip()\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        copy = ' '.join(w for w in copy.split() if w not in stop_words)\n",
    "    return copy\n",
    "\n",
    "def tokenize_text(text):\n",
    "    copy = tokenizer.tokenize(text)\n",
    "    return copy\n",
    "\n",
    "# copy the dataframes to not break anything when re-running some cells in the notebook.\n",
    "docs_copy = docs.copy(deep=True)\n",
    "queries_copy = queries_training.copy(deep=True)\n",
    "print(\"Preprocessing docs\")\n",
    "docs_copy[\"tokens\"] = docs_copy[\"AB\"].progress_apply(preprocess_text)\n",
    "print(\"Tokenizing docs\")\n",
    "docs_copy[\"tokens\"] = docs_copy[\"tokens\"].progress_apply(tokenize_text)\n",
    "print(\"Preprocessing queries\")\n",
    "queries_copy[\"tokens\"] = queries_copy[\"query\"].progress_apply(preprocess_text)\n",
    "print(\"Tokenizing queriess\")\n",
    "queries_copy[\"tokens\"] = queries_copy[\"tokens\"].progress_apply(tokenize_text)\n",
    "\n",
    "docs_copy.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results into a df\n",
    "def save_parquet(df, path):\n",
    "    if not os.path.exists(path):\n",
    "        df.to_parquet(path, engine=\"fastparquet\", index=False)\n",
    "\n",
    "path_docs = \"../data/docs.parquet\"\n",
    "path_queries = \"../data/queries.parquet\"\n",
    "\n",
    "save_parquet(docs_copy, path_docs)\n",
    "save_parquet(queries_copy, path_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402369\n"
     ]
    }
   ],
   "source": [
    "# load parquet\n",
    "path_docs = \"../data/docs.parquet\"\n",
    "path_queries = \"../data/queries.parquet\"\n",
    "\n",
    "\n",
    "docs_copy = pd.read_parquet(path_docs, engine=\"fastparquet\")\n",
    "queries_copy = pd.read_parquet(path_queries, engine=\"fastparquet\")\n",
    "print(docs_copy.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, the fun part - bert.\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def get_embeddings(tokens, window=512, overlap=50):\n",
    "    window_size = window - 2\n",
    "    step = window_size - overlap\n",
    "    embeddings = []\n",
    "    for i in range(0, len(tokens), step):\n",
    "        subset = tokens[i:i+window_size]\n",
    "        subset = [tokenizer.cls_token] + subset + [tokenizer.sep_token]\n",
    "        ids = tokenizer.convert_tokens_to_ids(subset)\n",
    "        masks = [1] * len(ids)\n",
    "        ids_tensor = torch.tensor([ids]).to(device)\n",
    "        mask_tensor = torch.tensor([masks]).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(ids_tensor, attention_mask=mask_tensor)\n",
    "            cls = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy() \n",
    "            embeddings.append(cls)\n",
    "    return np.mean(embeddings, axis=0)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 72493/402369 [06:36<28:47, 190.92it/s]c:\\StudySoftware\\anaconda3\\envs\\info-retrieval\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 402369/402369 [36:44<00:00, 182.56it/s]\n"
     ]
    }
   ],
   "source": [
    "docs_copy[\"embeddings\"] = docs_copy[\"tokens\"].progress_apply(get_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docs_embeddings = docs_copy[[\"PMID\", \"embeddings\"]]\n",
    "path_docs = \"../data/doc_embeddings.npz\"\n",
    "invalid_rows = docs_copy[docs_copy['embeddings'].apply(lambda x: x.size != 768)]\n",
    "invalid_pmids = set(invalid_rows['PMID'].tolist())\n",
    "\n",
    "# Filter out rows in `docs_copy` where the PMID is in `invalid_pmids`\n",
    "docs_embeddings = docs_embeddings[~docs_embeddings['PMID'].isin(invalid_pmids)].reset_index(drop=True)\n",
    "\n",
    "ids_list = docs_embeddings['PMID'].values.astype(np.int64)\n",
    "\n",
    "embeddings_list = docs_embeddings['embeddings'].values\n",
    "embeddings_array = np.vstack(embeddings_list)\n",
    "embeddings_array = embeddings_array.astype(np.float32)\n",
    "\n",
    "np.savez_compressed(path_docs, ids=ids_list, embeddings=embeddings_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 92.34it/s] \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [03:56<00:00,  5.02s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>relevant_docs</th>\n",
       "      <th>tokens</th>\n",
       "      <th>embedding</th>\n",
       "      <th>retrieved_docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"cyclin-dependent kinase inhibitor 1A (p21, Ci...</td>\n",
       "      <td>[11695244, 11751903, 11756412, 11762751, 11872...</td>\n",
       "      <td>[cy, ##cl, ##ind, ##ep, ##end, ##ent, kinase, ...</td>\n",
       "      <td>[-0.7932618, -0.1177296, -0.5675259, 0.0377362...</td>\n",
       "      <td>[12010809, 12445194, 11931770, 12027893, 11953...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"DEAD/H (Asp-Glu-Ala-Asp/His) box polypeptide ...</td>\n",
       "      <td>[12101238, 12527917]</td>\n",
       "      <td>[dead, ##h, as, ##pg, ##lu, ##ala, ##as, ##phi...</td>\n",
       "      <td>[-0.6105295, 0.026878148, -0.1451509, -0.00151...</td>\n",
       "      <td>[12509243, 12423350, 12036072, 12110569, 12435...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  \"cyclin-dependent kinase inhibitor 1A (p21, Ci...   \n",
       "1  \"DEAD/H (Asp-Glu-Ala-Asp/His) box polypeptide ...   \n",
       "\n",
       "                                       relevant_docs  \\\n",
       "0  [11695244, 11751903, 11756412, 11762751, 11872...   \n",
       "1                               [12101238, 12527917]   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [cy, ##cl, ##ind, ##ep, ##end, ##ent, kinase, ...   \n",
       "1  [dead, ##h, as, ##pg, ##lu, ##ala, ##as, ##phi...   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.7932618, -0.1177296, -0.5675259, 0.0377362...   \n",
       "1  [-0.6105295, 0.026878148, -0.1451509, -0.00151...   \n",
       "\n",
       "                                      retrieved_docs  \n",
       "0  [12010809, 12445194, 11931770, 12027893, 11953...  \n",
       "1  [12509243, 12423350, 12036072, 12110569, 12435...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# testing\n",
    "queries_copy[\"embedding\"] = queries_copy[\"tokens\"].progress_apply(get_embeddings)\n",
    "\n",
    "def retrieve_docs(comparison_vector, top_n=10, filepath=\"../data/doc_embeddings.npz\"):\n",
    "    data = np.load(filepath)\n",
    "    vectors = data[\"embeddings\"]\n",
    "    pmids = data[\"ids\"]\n",
    "    \n",
    "    comparison_vector = comparison_vector.reshape(1, -1)\n",
    "    cos_similarities = cosine_similarity(comparison_vector, vectors).flatten()\n",
    "    \n",
    "    top_indices = cos_similarities.argsort()[-top_n:][::-1]\n",
    "    #top_docs = [(pmids[index], cos_similarities[index]) for index in top_indices]\n",
    "    top_docs = [pmids[index] for index in top_indices]\n",
    "    \n",
    "    return top_docs\n",
    "\n",
    "result = queries_copy.copy(deep=True)\n",
    "\n",
    "result[\"retrieved_docs\"] = result[\"embedding\"].progress_apply(retrieve_docs)\n",
    "result.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               query  \\\n",
      "0  \"cyclin-dependent kinase inhibitor 1A (p21, Ci...   \n",
      "1  \"DEAD/H (Asp-Glu-Ala-Asp/His) box polypeptide ...   \n",
      "2  ets variant gene 6 (TEL oncogene) in Homo sapiens   \n",
      "\n",
      "                                       relevant_docs  \\\n",
      "0  [11695244, 11751903, 11756412, 11762751, 11872...   \n",
      "1                               [12101238, 12527917]   \n",
      "2  [11861293, 11861295, 12080468, 12091359, 12127...   \n",
      "\n",
      "                                              tokens  \\\n",
      "0  [cy, ##cl, ##ind, ##ep, ##end, ##ent, kinase, ...   \n",
      "1  [dead, ##h, as, ##pg, ##lu, ##ala, ##as, ##phi...   \n",
      "2  [et, ##s, variant, gene, 6, tel, on, ##co, ##g...   \n",
      "\n",
      "                                           embedding  \\\n",
      "0  [-0.7932618, -0.1177296, -0.5675259, 0.0377362...   \n",
      "1  [-0.6105295, 0.026878148, -0.1451509, -0.00151...   \n",
      "2  [-0.47980258, -0.14554822, -0.5667131, 0.12695...   \n",
      "\n",
      "                                      retrieved_docs  match_percentage  \n",
      "0  [12010809, 12445194, 11931770, 12027893, 11953...               0.0  \n",
      "1  [12509243, 12423350, 12036072, 12110569, 12435...               0.0  \n",
      "2  [12198117, 12072520, 12449812, 12370086, 12388...               0.0  \n"
     ]
    }
   ],
   "source": [
    "def compute_match_percentage(row):\n",
    "    retrieved = set(row['retrieved_docs'])\n",
    "    relevant = set(row['relevant_docs'])\n",
    "    if not relevant:\n",
    "        return 0.0  # Avoid division by zero; adjust as needed\n",
    "    num_matches = len(retrieved & relevant)\n",
    "    percentage = (num_matches / len(relevant)) * 100\n",
    "    return percentage\n",
    "\n",
    "# Apply the function to each row and assign the result to a new column\n",
    "result['match_percentage'] = result.apply(compute_match_percentage, axis=1)\n",
    "print(result.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 285/285 [00:00<00:00, 14250.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 285/285 [00:00<00:00, 626.37it/s]\n"
     ]
    }
   ],
   "source": [
    "selected_docs_copy = selected_docs.copy(deep=True)\n",
    "print(\"Preprocessing docs\")\n",
    "selected_docs_copy[\"tokens\"] = selected_docs_copy[\"AB\"].progress_apply(preprocess_text)\n",
    "print(\"Tokenizing docs\")\n",
    "selected_docs_copy[\"tokens\"] = selected_docs_copy[\"tokens\"].progress_apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 285/285 [00:01<00:00, 151.69it/s]\n"
     ]
    }
   ],
   "source": [
    "selected_docs_copy[\"embeddings\"] = selected_docs_copy[\"tokens\"].progress_apply(get_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 824.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "selected_queries = queries_copy.copy(deep=True)\n",
    "def retrieve_docs(comparison_vector, top_n=10, dataset=selected_docs_copy):\n",
    "    vectors = dataset[\"embeddings\"].values\n",
    "    pmids = dataset[\"PMID\"].values.astype(np.int64)\n",
    "    vectors = np.vstack(vectors)\n",
    "    vectors = vectors.astype(np.float32)\n",
    "\n",
    "    comparison_vector = comparison_vector.reshape(1, -1)\n",
    "    cos_similarities = cosine_similarity(comparison_vector, vectors).flatten()\n",
    "    top_indices = cos_similarities.argsort()[-top_n:][::-1]\n",
    "    #top_docs = [(pmids[index], cos_similarities[index]) for index in top_indices]\n",
    "    top_docs = [pmids[index] for index in top_indices]\n",
    "    \n",
    "    return top_docs\n",
    "selected_queries[\"retrieved_docs\"] = selected_queries[\"embedding\"].progress_apply(retrieve_docs)\n",
    "print(result[\"match_percentage\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       doc_id  cosine_similarity  relevant?\n",
      "0    11905808           0.882718          0\n",
      "1    12052963           0.874792          0\n",
      "2    12370803           0.870549          0\n",
      "3    12172548           0.868151          0\n",
      "4    12429910           0.867177          1\n",
      "..        ...                ...        ...\n",
      "280  12039527           0.763055          0\n",
      "281  12021067           0.757628          0\n",
      "282  12393285           0.750171          0\n",
      "283  12210105           0.743329          0\n",
      "284  11906328           0.721113          0\n",
      "\n",
      "[285 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def retrieve_all_docs_df(comparison_vector, dataset):\n",
    "    vectors = dataset[\"embeddings\"].values\n",
    "    pmids = dataset[\"PMID\"].values.astype(np.int64)\n",
    "    \n",
    "    # Stack embeddings into a 2D NumPy array\n",
    "    vectors = np.vstack(vectors).astype(np.float32)\n",
    "\n",
    "    # Ensure the comparison vector has the correct shape and type\n",
    "    comparison_vector = comparison_vector.reshape(1, -1).astype(np.float32)\n",
    "    \n",
    "    # Compute cosine similarities between the comparison vector and all document vectors\n",
    "    cos_similarities = cosine_similarity(comparison_vector, vectors).flatten()\n",
    "    \n",
    "    # Create a DataFrame with 'doc_id' and 'cosine_similarity' columns\n",
    "    df = pd.DataFrame({\n",
    "        'doc_id': pmids,\n",
    "        'cosine_similarity': cos_similarities\n",
    "    })\n",
    "    \n",
    "    # Sort the DataFrame by 'cosine_similarity' in descending order\n",
    "    df_sorted = df.sort_values(by='cosine_similarity', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return df_sorted\n",
    "\n",
    "relevant_docs = set(selected_queries[\"relevant_docs\"].iloc[0])\n",
    "df_retrieved = retrieve_all_docs_df(selected_queries[\"embedding\"].iloc[0], selected_docs_copy)\n",
    "df_retrieved['relevant?'] = df_retrieved['doc_id'].apply(lambda x: 1 if x in relevant_docs else 0)\n",
    "\n",
    "print(df_retrieved)\n",
    "df_retrieved.to_csv(\"thisisbad.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info-retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
