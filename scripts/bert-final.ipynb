{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vitaf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# no lowercasing here, as we do it ourselves later.\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=False)\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../data/trec-medline.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>AB</th>\n",
       "      <th>AD</th>\n",
       "      <th>CY</th>\n",
       "      <th>DA</th>\n",
       "      <th>DCOM</th>\n",
       "      <th>DP</th>\n",
       "      <th>EDAT</th>\n",
       "      <th>ID</th>\n",
       "      <th>IP</th>\n",
       "      <th>...</th>\n",
       "      <th>CON</th>\n",
       "      <th>CIN</th>\n",
       "      <th>RPF</th>\n",
       "      <th>RPI</th>\n",
       "      <th>SPIN</th>\n",
       "      <th>RIN</th>\n",
       "      <th>ROF</th>\n",
       "      <th>ORI</th>\n",
       "      <th>UOF</th>\n",
       "      <th>UIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We present an evaluation of the accuracy and p...</td>\n",
       "      <td>Department of Molecular Biology and Skaggs Ins...</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>20011105.0</td>\n",
       "      <td>20020401.0</td>\n",
       "      <td>2001 Sep</td>\n",
       "      <td>2001/11/06 10:00</td>\n",
       "      <td>GM56879/GM/NIGMS</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>An analysis is presented of experimental versu...</td>\n",
       "      <td>Department of Medical Biosciences, Medical Bio...</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>20011105.0</td>\n",
       "      <td>20020401.0</td>\n",
       "      <td>2001 Sep</td>\n",
       "      <td>2001/11/06 10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The global fold of maltose binding protein in ...</td>\n",
       "      <td>Protein Engineering Network Center of Excellen...</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>20011105.0</td>\n",
       "      <td>20020401.0</td>\n",
       "      <td>2001 Sep</td>\n",
       "      <td>2001/11/06 10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A general method is presented for magnetic fie...</td>\n",
       "      <td>Molecular Structure Division, National Institu...</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>20011105.0</td>\n",
       "      <td>20020401.0</td>\n",
       "      <td>2001 Sep</td>\n",
       "      <td>2001/11/06 10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The dependence between the anomeric carbon che...</td>\n",
       "      <td>Department of Chemistry &amp; Biochemistry, Univer...</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>20011105.0</td>\n",
       "      <td>20020401.0</td>\n",
       "      <td>2001 Sep</td>\n",
       "      <td>2001/11/06 10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                                 AB  \\\n",
       "0      1  We present an evaluation of the accuracy and p...   \n",
       "1      2  An analysis is presented of experimental versu...   \n",
       "2      3  The global fold of maltose binding protein in ...   \n",
       "3      4  A general method is presented for magnetic fie...   \n",
       "4      5  The dependence between the anomeric carbon che...   \n",
       "\n",
       "                                                  AD           CY          DA  \\\n",
       "0  Department of Molecular Biology and Skaggs Ins...  Netherlands  20011105.0   \n",
       "1  Department of Medical Biosciences, Medical Bio...  Netherlands  20011105.0   \n",
       "2  Protein Engineering Network Center of Excellen...  Netherlands  20011105.0   \n",
       "3  Molecular Structure Division, National Institu...  Netherlands  20011105.0   \n",
       "4  Department of Chemistry & Biochemistry, Univer...  Netherlands  20011105.0   \n",
       "\n",
       "         DCOM        DP              EDAT                ID IP  ...  CON  CIN  \\\n",
       "0  20020401.0  2001 Sep  2001/11/06 10:00  GM56879/GM/NIGMS  1  ...  NaN  NaN   \n",
       "1  20020401.0  2001 Sep  2001/11/06 10:00               NaN  1  ...  NaN  NaN   \n",
       "2  20020401.0  2001 Sep  2001/11/06 10:00               NaN  1  ...  NaN  NaN   \n",
       "3  20020401.0  2001 Sep  2001/11/06 10:00               NaN  1  ...  NaN  NaN   \n",
       "4  20020401.0  2001 Sep  2001/11/06 10:00               NaN  1  ...  NaN  NaN   \n",
       "\n",
       "   RPF  RPI SPIN  RIN  ROF  ORI  UOF  UIN  \n",
       "0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_rows = df.iloc[::2].reset_index(drop=True)[[\"index\"]]\n",
    "id_rows[\"index\"] = id_rows[\"index\"].apply(lambda x: int(x[\"_id\"]))\n",
    "content_rows = df.iloc[1::2].reset_index(drop=True).drop(labels=[\"index\"], axis=1)\n",
    "combined_df = pd.concat([id_rows, content_rows], axis=1)\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>AB</th>\n",
       "      <th>PMID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We present an evaluation of the accuracy and p...</td>\n",
       "      <td>11693564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>An analysis is presented of experimental versu...</td>\n",
       "      <td>11693565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The global fold of maltose binding protein in ...</td>\n",
       "      <td>11693566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A general method is presented for magnetic fie...</td>\n",
       "      <td>11693567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The dependence between the anomeric carbon che...</td>\n",
       "      <td>11693568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                                 AB      PMID\n",
       "0      1  We present an evaluation of the accuracy and p...  11693564\n",
       "1      2  An analysis is presented of experimental versu...  11693565\n",
       "2      3  The global fold of maltose binding protein in ...  11693566\n",
       "3      4  A general method is presented for magnetic fie...  11693567\n",
       "4      5  The dependence between the anomeric carbon che...  11693568"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = combined_df[[\"index\", \"AB\", \"PMID\"]]\n",
    "docs = docs.astype({\"index\": int, \"PMID\": int})\n",
    "docs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index    0\n",
      "query    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# load queries\n",
    "queries = pd.DataFrame(columns=[\"index\", \"query\"])\n",
    "\n",
    "with open(\"../data/training-queries-simple.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "data = []\n",
    "for line in lines:\n",
    "    x = line.strip().split(\"\\t\")\n",
    "    if len(x) >= 2:  \n",
    "        data.append({\"index\": int(x[0]), \"query\": x[1]})\n",
    "    else:\n",
    "        raise ValueError(\"wtf\")\n",
    "queries = pd.concat([queries, pd.DataFrame(data)], ignore_index=True)\n",
    "queries.head(5)\n",
    "print(queries.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index         0\n",
      "AB       123568\n",
      "PMID          0\n",
      "dtype: int64\n",
      "402369\n",
      "401929\n"
     ]
    }
   ],
   "source": [
    "# drop missings\n",
    "print(docs.isna().sum())\n",
    "docs = docs.dropna()\n",
    "def remove_short_strings(df, column_name):\n",
    "    pattern = re.compile(r'\\W+')\n",
    "    filtered_df = df[df[column_name].apply(\n",
    "        lambda x: isinstance(x, str) and len(pattern.sub('', x)) >= 20\n",
    "    )].copy()\n",
    "    filtered_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return filtered_df\n",
    "print(docs.shape[0])\n",
    "docs = remove_short_strings(docs, \"AB\")\n",
    "print(docs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1529\n"
     ]
    }
   ],
   "source": [
    "# find max words\n",
    "max_words = docs['AB'].apply(lambda x: len(x.split())).max()\n",
    "print(max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  query_index doc_index relevant\n",
      "0           1  11642719        1\n",
      "1           1  11695244        1\n",
      "2           1  11700040        1\n",
      "3           1  11733969        1\n",
      "4           1  11741909        1\n",
      "query_index    0\n",
      "doc_index      0\n",
      "relevant       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# load query results\n",
    "query_res = pd.DataFrame(columns=[\"query_index\", \"doc_index\", \"relevant\"])\n",
    "\n",
    "with open(\"../data/training-qrels.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "data = []\n",
    "for line in lines:\n",
    "    x = line.strip().split(\"\\t\")\n",
    "    if len(x) >= 4:  \n",
    "        data.append({\"query_index\": int(x[0]), \"doc_index\": int(x[2]), \"relevant\": int(x[3])})\n",
    "    else:\n",
    "        raise ValueError(\"wtf\")\n",
    "query_res = pd.concat([query_res, pd.DataFrame(data)], ignore_index=True)\n",
    "print(query_res.head(5))\n",
    "print(query_res.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>query</th>\n",
       "      <th>relevant_docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"cyclin-dependent kinase inhibitor 1A (p21, Ci...</td>\n",
       "      <td>[11642719, 11695244, 11700040, 11733969, 11741...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"DEAD/H (Asp-Glu-Ala-Asp/His) box polypeptide ...</td>\n",
       "      <td>[12101238, 12527917]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ets variant gene 6 (TEL oncogene) in Homo sapiens</td>\n",
       "      <td>[11731410, 11861293, 11861295, 12080468, 12091...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>fibroblast growth factor 7 (keratinocyte growt...</td>\n",
       "      <td>[11937263, 11943656, 11973338, 12008951, 12016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"glycine receptor, alpha 1 (startle disease/hy...</td>\n",
       "      <td>[11580237, 11781706, 11973623, 11981020, 11981...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index                                              query  \\\n",
       "0     1  \"cyclin-dependent kinase inhibitor 1A (p21, Ci...   \n",
       "1     2  \"DEAD/H (Asp-Glu-Ala-Asp/His) box polypeptide ...   \n",
       "2     3  ets variant gene 6 (TEL oncogene) in Homo sapiens   \n",
       "3     4  fibroblast growth factor 7 (keratinocyte growt...   \n",
       "4     5  \"glycine receptor, alpha 1 (startle disease/hy...   \n",
       "\n",
       "                                       relevant_docs  \n",
       "0  [11642719, 11695244, 11700040, 11733969, 11741...  \n",
       "1                               [12101238, 12527917]  \n",
       "2  [11731410, 11861293, 11861295, 12080468, 12091...  \n",
       "3  [11937263, 11943656, 11973338, 12008951, 12016...  \n",
       "4  [11580237, 11781706, 11973623, 11981020, 11981...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine queries and results\n",
    "\n",
    "filtered_df = query_res[query_res[\"relevant\"] == 1]\n",
    "grouped_df = filtered_df.groupby('query_index')['doc_index'].apply(list).reset_index()\n",
    "grouped_df = grouped_df.rename(columns={'doc_index': 'relevant_docs'})\n",
    "queries_training = pd.concat([queries, grouped_df], axis=1)\n",
    "queries_training = queries_training.drop(columns=[\"query_index\"])\n",
    "queries_training.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>query</th>\n",
       "      <th>relevant_docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"cyclin-dependent kinase inhibitor 1A (p21, Ci...</td>\n",
       "      <td>[11642719, 11695244, 11700040, 11733969, 11741...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"DEAD/H (Asp-Glu-Ala-Asp/His) box polypeptide ...</td>\n",
       "      <td>[12101238, 12527917]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ets variant gene 6 (TEL oncogene) in Homo sapiens</td>\n",
       "      <td>[11731410, 11861293, 11861295, 12080468, 12091...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>fibroblast growth factor 7 (keratinocyte growt...</td>\n",
       "      <td>[11937263, 11943656, 11973338, 12008951, 12016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"glycine receptor, alpha 1 (startle disease/hy...</td>\n",
       "      <td>[11580237, 11781706, 11973623, 11981020, 11981...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index                                              query  \\\n",
       "0     1  \"cyclin-dependent kinase inhibitor 1A (p21, Ci...   \n",
       "1     2  \"DEAD/H (Asp-Glu-Ala-Asp/His) box polypeptide ...   \n",
       "2     3  ets variant gene 6 (TEL oncogene) in Homo sapiens   \n",
       "3     4  fibroblast growth factor 7 (keratinocyte growt...   \n",
       "4     5  \"glycine receptor, alpha 1 (startle disease/hy...   \n",
       "\n",
       "                                       relevant_docs  \n",
       "0  [11642719, 11695244, 11700040, 11733969, 11741...  \n",
       "1                               [12101238, 12527917]  \n",
       "2  [11731410, 11861293, 11861295, 12080468, 12091...  \n",
       "3  [11937263, 11943656, 11973338, 12008951, 12016...  \n",
       "4  [11580237, 11781706, 11973623, 11981020, 11981...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect final datasetsts\n",
    "queries_training.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>AB</th>\n",
       "      <th>PMID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We present an evaluation of the accuracy and p...</td>\n",
       "      <td>11693564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>An analysis is presented of experimental versu...</td>\n",
       "      <td>11693565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The global fold of maltose binding protein in ...</td>\n",
       "      <td>11693566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A general method is presented for magnetic fie...</td>\n",
       "      <td>11693567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The dependence between the anomeric carbon che...</td>\n",
       "      <td>11693568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                                 AB      PMID\n",
       "0      1  We present an evaluation of the accuracy and p...  11693564\n",
       "1      2  An analysis is presented of experimental versu...  11693565\n",
       "2      3  The global fold of maltose binding protein in ...  11693566\n",
       "3      4  A general method is presented for magnetic fie...  11693567\n",
       "4      5  The dependence between the anomeric carbon che...  11693568"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{12147208, 12147209, 11861518, 11688978, 11822867, 11714840, 12027934, 11374883, 11406125, 11042116, 11717190, 11700040, 11781193, 11781706, 11564874, 11580237, 11882578, 11846485, 11642719, 11685227, 11466351, 11841916, 11752574, 11752575, 11779460, 11740559, 11727760, 12412576, 11686318, 11441070, 11809712, 11743158, 11701948, 11749055, 11842244, 11748297, 11733969, 11731410, 11741909, 11752172, 11751405, 12161015}\n",
      "Number of relevant docs: 327\n",
      "Number of existing docs in 'docs' DataFrame: 285\n",
      "Number of missing docs: 42\n"
     ]
    }
   ],
   "source": [
    "# check if all doc ids from queries are in the dataset (after removing missings)\n",
    "unique_relevant_docs = set(queries_training['relevant_docs'].explode())\n",
    "existing_docs = unique_relevant_docs.intersection(docs.PMID)\n",
    "missing_docs = unique_relevant_docs.difference(docs.PMID)\n",
    "\n",
    "print(missing_docs)\n",
    "print(f\"Number of relevant docs: {len(unique_relevant_docs)}\")\n",
    "print(f\"Number of existing docs in 'docs' DataFrame: {len(existing_docs)}\")\n",
    "print(f\"Number of missing docs: {len(missing_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a smaller dataset\n",
    "existing_docs = set(unique_relevant_docs).intersection(set(docs['PMID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ofc there are missings relevant texts with no abstract. nice dataset:)\n",
    "def filter_missing_docs(doc_list):\n",
    "    return [doc for doc in doc_list if doc in existing_docs]\n",
    "    \n",
    "queries_training['relevant_docs'] = queries_training['relevant_docs'].apply(filter_missing_docs)\n",
    "# remove quries with no docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_training = queries_training[queries_training['relevant_docs'].apply(lambda x: len(x) > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_training = queries_training.drop(columns=[\"index\"])\n",
    "docs = docs.drop(columns=[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, remove_stopwords=True):\n",
    "    copy = text\n",
    "    copy = copy.lower()\n",
    "    # remove punctuation\n",
    "    copy = re.sub(r\"[^\\w\\s]\", '', copy)\n",
    "    # remove double whitespaces.\n",
    "    copy = re.sub(r'\\s+', ' ', copy).strip()\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        copy = ' '.join(w for w in copy.split() if w not in stop_words)\n",
    "    return copy\n",
    "\n",
    "def tokenize_text(text):\n",
    "    copy = tokenizer.tokenize(text)\n",
    "    return copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(row, k=10):\n",
    "    retrieved = row['retrieved_docs'][:k]\n",
    "    relevant = set(row['relevant_docs'])\n",
    "    if k == 0:\n",
    "        return 0.0\n",
    "    num_relevant_in_retrieved = len(set(retrieved) & relevant)\n",
    "    precision = (num_relevant_in_retrieved / k) * 100\n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\StudySoftware\\anaconda3\\envs\\info-retrieval\\lib\\site-packages\\transformers\\modeling_utils.py:345: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(resolved_archive_file, map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "def get_embeddings_words(tokens, window=512):\n",
    "    window = window - 2\n",
    "    embeddings = []\n",
    "    for i in range(0, len(tokens), window):\n",
    "        subset = tokens[i:i+window]\n",
    "        subset = [tokenizer.cls_token] + subset + [tokenizer.sep_token]\n",
    "        ids = tokenizer.convert_tokens_to_ids(subset)\n",
    "        masks = [1] * len(ids)\n",
    "        ids_tensor = torch.tensor([ids]).to(device)\n",
    "        mask_tensor = torch.tensor([masks]).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(ids_tensor, attention_mask=mask_tensor)\n",
    "            token_embeddings = outputs[0].squeeze().cpu().numpy()\n",
    "            embeddings.extend(token_embeddings)\n",
    "        \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf embedding function\n",
    "def get_embeddings_words_tfidf(tokens, doc_list):\n",
    "    # this function is called on a dataframe, once for each doc/query in the dataframe. tokens is a list of \n",
    "    # all the tokens in that doc/query, passed from the dataframe for each doc. doc_list does not change, so \n",
    "    # it's not changed. doc_list is a dataframe this function is called on:))))), but not row-by-row.\n",
    "    # I would personally look into tf-idf and precompute idf before this function, passing the idf dataframe\n",
    "    # instead in place of doc_list, as idf is the same for the entire corspus. This would prevent a lot of\n",
    "    # unnecessary computations.\n",
    "    # tokens = list of tokens for one doc/query\n",
    "    # return matrix of embeddings = a list of vectors, where each vector - embedding of a word in a sequence.\n",
    "    # vectors should be of the same dimension for all input sequences, \n",
    "    # the number of vectors in the matrix list doens't matter.\n",
    "    # e.g. [[1, 2, 3], [1, 2, 3]] returned for one set of tokens and [[1, 2, 3]] for another, but\n",
    "    # [[1, 2, 3], [1, 2, 3]] and [[1, 2, 3, 4], [1, 2, 3, 4]] is bad. Each token in any input sequence\n",
    "    # should get a vector feature of a fixed size. See the example of returned docs.\n",
    "    # when doing tf-idf, please only use token column, do not use text column.\n",
    "    # to speed up computing, you can move parts of tf-idf to a separate function and set it to a variable\n",
    "    # (e.g. parts which are the same, like idf).\n",
    "    return [[1, 2], [1, 2], [3, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:00<00:00, 13335.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:00<00:00, 672.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing queries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing queriess\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 8630.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# try word-level\n",
    "# Select the subset of the docs present in the query answers.\n",
    "selected_docs = docs[docs['PMID'].isin(existing_docs)]\n",
    "selected_docs_copy = selected_docs.copy(deep=True)\n",
    "\n",
    "# preprocess and tokenize docs\n",
    "print(\"Preprocessing docs\")\n",
    "selected_docs_copy[\"tokens\"] = selected_docs_copy[\"AB\"].progress_apply(preprocess_text)\n",
    "print(\"Tokenizing docs\")\n",
    "selected_docs_copy[\"tokens\"] = selected_docs_copy[\"tokens\"].progress_apply(tokenize_text)\n",
    "\n",
    "# preprocess and tokenize queries\n",
    "selected_queries = queries_training.copy(deep=True)\n",
    "print(\"Preprocessing queries\")\n",
    "selected_queries[\"tokens\"] = selected_queries[\"query\"].progress_apply(preprocess_text)\n",
    "print(\"Tokenizing queriess\")\n",
    "selected_queries[\"tokens\"] = selected_queries[\"tokens\"].progress_apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copies for tf-idf\n",
    "selected_docs_tfidf = selected_docs_copy.copy(deep=True)\n",
    "selected_queries_tfidf = selected_queries.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:02<00:00, 121.96it/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 141.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>relevant_docs</th>\n",
       "      <th>tokens</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"cyclin-dependent kinase inhibitor 1A (p21, Ci...</td>\n",
       "      <td>[11695244, 11751903, 11756412, 11762751, 11872...</td>\n",
       "      <td>[cy, ##cl, ##ind, ##ep, ##end, ##ent, kinase, ...</td>\n",
       "      <td>[[-0.79326123, -0.11772958, -0.56752604, 0.037...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"DEAD/H (Asp-Glu-Ala-Asp/His) box polypeptide ...</td>\n",
       "      <td>[12101238, 12527917]</td>\n",
       "      <td>[dead, ##h, as, ##pg, ##lu, ##ala, ##as, ##phi...</td>\n",
       "      <td>[[-0.6105297, 0.026877305, -0.14515096, -0.001...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  \"cyclin-dependent kinase inhibitor 1A (p21, Ci...   \n",
       "1  \"DEAD/H (Asp-Glu-Ala-Asp/His) box polypeptide ...   \n",
       "\n",
       "                                       relevant_docs  \\\n",
       "0  [11695244, 11751903, 11756412, 11762751, 11872...   \n",
       "1                               [12101238, 12527917]   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [cy, ##cl, ##ind, ##ep, ##end, ##ent, kinase, ...   \n",
       "1  [dead, ##h, as, ##pg, ##lu, ##ala, ##as, ##phi...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [[-0.79326123, -0.11772958, -0.56752604, 0.037...  \n",
       "1  [[-0.6105297, 0.026877305, -0.14515096, -0.001...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate embedding matrices using bert\n",
    "selected_docs_copy[\"embeddings\"] = selected_docs_copy[\"tokens\"].progress_apply(get_embeddings_words)\n",
    "selected_queries[\"embedding\"] = selected_queries[\"tokens\"].progress_apply(get_embeddings_words)\n",
    "selected_queries.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:00<00:00, 22700.33it/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 46669.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>relevant_docs</th>\n",
       "      <th>tokens</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"cyclin-dependent kinase inhibitor 1A (p21, Ci...</td>\n",
       "      <td>[11695244, 11751903, 11756412, 11762751, 11872...</td>\n",
       "      <td>[cy, ##cl, ##ind, ##ep, ##end, ##ent, kinase, ...</td>\n",
       "      <td>[[-0.79326123, -0.11772958, -0.56752604, 0.037...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"DEAD/H (Asp-Glu-Ala-Asp/His) box polypeptide ...</td>\n",
       "      <td>[12101238, 12527917]</td>\n",
       "      <td>[dead, ##h, as, ##pg, ##lu, ##ala, ##as, ##phi...</td>\n",
       "      <td>[[-0.6105297, 0.026877305, -0.14515096, -0.001...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  \"cyclin-dependent kinase inhibitor 1A (p21, Ci...   \n",
       "1  \"DEAD/H (Asp-Glu-Ala-Asp/His) box polypeptide ...   \n",
       "\n",
       "                                       relevant_docs  \\\n",
       "0  [11695244, 11751903, 11756412, 11762751, 11872...   \n",
       "1                               [12101238, 12527917]   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [cy, ##cl, ##ind, ##ep, ##end, ##ent, kinase, ...   \n",
       "1  [dead, ##h, as, ##pg, ##lu, ##ala, ##as, ##phi...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [[-0.79326123, -0.11772958, -0.56752604, 0.037...  \n",
       "1  [[-0.6105297, 0.026877305, -0.14515096, -0.001...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate embedding matrices using tf-idf\n",
    "selected_docs_tfidf[\"embeddings\"] = selected_docs_tfidf[\"tokens\"].progress_apply(\n",
    "    get_embeddings_words_tfidf, doc_list=selected_docs_tfidf)\n",
    "selected_queries_tfidf[\"embedding\"] = selected_queries_tfidf[\"tokens\"].progress_apply(\n",
    "    get_embeddings_words_tfidf, doc_list=selected_docs_tfidf)\n",
    "selected_queries.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_all_docs_df(query_embeddings, dataset, top_n=10):\n",
    "    # Convert query embeddings to a NumPy array\n",
    "    query_embeddings = np.array(query_embeddings).astype(np.float32)\n",
    "\n",
    "    # Extract document embeddings and PMIDs\n",
    "    vectors_list = dataset[\"embeddings\"].values\n",
    "    pmids = dataset[\"PMID\"].values.astype(np.int64)\n",
    "\n",
    "    # Initialize a list to store similarity scores\n",
    "    scores = []\n",
    "\n",
    "    # Iterate over each document's embeddings\n",
    "    for doc_emb in vectors_list:\n",
    "        # Convert document embeddings to a NumPy array\n",
    "        doc_emb = np.array(doc_emb).astype(np.float32)\n",
    "        \n",
    "        # Compute the cosine similarity matrix between query and document embeddings\n",
    "        cos_sim_matrix = cosine_similarity(query_embeddings, doc_emb)\n",
    "        \n",
    "        # For each query embedding, find the maximum similarity with document embeddings\n",
    "        max_similarities = np.max(cos_sim_matrix, axis=1)\n",
    "        \n",
    "        # Average the maximum similarities to get a single score for the document\n",
    "        score = np.mean(max_similarities)\n",
    "        scores.append(score)\n",
    "    \n",
    "    # Create a DataFrame with 'doc_id' and 'similarity_score' columns\n",
    "    df = pd.DataFrame({\n",
    "        'doc_id': pmids,\n",
    "        'similarity_score': scores\n",
    "    })\n",
    "\n",
    "    # Sort the DataFrame by 'similarity_score' in descending order\n",
    "    df_sorted = df.sort_values(by='similarity_score', ascending=False).reset_index(drop=True)\n",
    "    top_doc_ids = df_sorted['doc_id'].head(top_n).tolist()\n",
    "    \n",
    "    return top_doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:07<00:00,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.085106382978722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# bert result\n",
    "selected_queries[\"retrieved_docs\"] = selected_queries[\"embedding\"].progress_apply(retrieve_all_docs_df, \n",
    "                                                                                  dataset=selected_docs_copy)\n",
    "selected_queries[\"precission_at_k\"] = selected_queries.apply(precision_at_k, axis=1)\n",
    "print(selected_queries[\"precission_at_k\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:02<00:00, 19.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.127659574468085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# tf-idf result\n",
    "selected_queries_tfidf[\"retrieved_docs\"] = selected_queries_tfidf[\"embedding\"].progress_apply(retrieve_all_docs_df, \n",
    "                                                                                  dataset=selected_docs_tfidf)\n",
    "selected_queries_tfidf[\"precission_at_k\"] = selected_queries_tfidf.apply(precision_at_k, axis=1)\n",
    "print(selected_queries_tfidf[\"precission_at_k\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: 7.095797745078743\n",
      "p-value (one-tailed): 2.9252322812446207e-09\n"
     ]
    }
   ],
   "source": [
    "# paired t-test\n",
    "from scipy.stats import ttest_rel\n",
    "from scipy import stats\n",
    "\n",
    "bert_scores = selected_queries[\"precission_at_k\"].to_numpy()\n",
    "tfidf_scores = selected_queries_tfidf[\"precission_at_k\"].to_numpy()\n",
    "\n",
    "t_stat, p_two_tailed = ttest_rel(bert_scores, tfidf_scores)\n",
    "\n",
    "p_one_tailed = stats.t.sf(t_stat, df=len(bert_scores - 1))\n",
    "\n",
    "print(f\"t-statistic: {t_stat}\")\n",
    "print(f\"p-value (one-tailed): {p_one_tailed}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info-retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
